{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGSOr7pdJS4GKQ9HykkHA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matheus3788/AulaDWIII_Exemplo/blob/main/PI_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "oyjssCSP9FeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjJHNUCE6jTE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import unicodedata\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_treinamento = pd.read_excel('Base_Pedidos.xlsx', engine='openpyxl')\n",
        "df_treinamento['request_normalized'] = df_treinamento['request']"
      ],
      "metadata": {
        "id": "PVeY7kyH6n46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acentos_para_sem_acento = {\n",
        "    'á': 'a', 'à': 'a', 'ã': 'a', 'â': 'a', 'ä': 'a',\n",
        "    'é': 'e', 'è': 'e', 'ê': 'e', 'ë': 'e',\n",
        "    'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
        "    'ó': 'o', 'ò': 'o', 'õ': 'o', 'ô': 'o', 'ö': 'o',\n",
        "    'ú': 'u', 'ù': 'u', 'û': 'u', 'ü': 'u',\n",
        "    'ç': 'c',\n",
        "    'Á': 'A', 'À': 'A', 'Ã': 'A', 'Â': 'A', 'Ä': 'A',\n",
        "    'É': 'E', 'È': 'E', 'Ê': 'E', 'Ë': 'E',\n",
        "    'Í': 'I', 'Ì': 'I', 'Î': 'I', 'Ï': 'I',\n",
        "    'Ó': 'O', 'Ò': 'O', 'Õ': 'O', 'Ô': 'O', 'Ö': 'O',\n",
        "    'Ú': 'U', 'Ù': 'U', 'Û': 'U', 'Ü': 'U',\n",
        "    'Ç': 'C'\n",
        "}\n",
        "\n",
        "def remover_acentos(texto):\n",
        "    texto_sem_acento = \"\"\n",
        "    for char in texto:\n",
        "        if char in acentos_para_sem_acento:\n",
        "            texto_sem_acento += acentos_para_sem_acento[char]\n",
        "        else:\n",
        "            texto_sem_acento += char\n",
        "    return texto_sem_acento\n",
        "\n",
        "df_treinamento['request_normalized'] = df_treinamento['request_normalized'].apply(\n",
        "    lambda x: re.sub(r'[^a-z0-9\\s]', '', remover_acentos(x).lower())\n",
        ")"
      ],
      "metadata": {
        "id": "p-laO-om8AIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treinamento['request_normalized'] = df_treinamento['request_normalized'].apply(lambda x: x.split())"
      ],
      "metadata": {
        "id": "DHvkl3sW8H3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_manual = {\n",
        "    'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'e',\n",
        "    'com', 'nao', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as',\n",
        "    'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'a', 'seu',\n",
        "    'sua', 'ou', 'ser', 'quando', 'muito', 'ha', 'nos', 'ja', 'esta',\n",
        "    'eu', 'também', 'so', 'pelo', 'pela', 'ate', 'isso', 'ela', 'entre'\n",
        "}\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    return [word for word in words if word not in stop_words_manual]\n",
        "\n",
        "df_treinamento['request_normalized'] = df_treinamento['request_normalized'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "3cK0dYbo8L4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treinamento['request_normalized_str'] = df_treinamento['request_normalized'].apply(lambda x: ' '.join(x))\n",
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "\n",
        "vector = vectorizer.fit_transform(df_treinamento['request_normalized_str'])\n",
        "X = pd.DataFrame.sparse.from_spmatrix(vector, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "y = df_treinamento['truthfulness']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensões do conjunto de treino:\", X_train.shape)\n",
        "print(\"Dimensões do conjunto de teste:\", X_test.shape)\n",
        "print(\"Rótulos de treino:\", y_train.shape)\n",
        "print(\"Rótulos de teste:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "Id0zntFa8QLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo = LogisticRegression(max_iter=1000, random_state=42)\n",
        "modelo.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QDsklKyr8rz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "1217f7kL8zoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_acentos(texto):\n",
        "    nfkd = unicodedata.normalize('NFKD', str(texto))\n",
        "    return \"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "\n",
        "def preprocessar_texto(texto):\n",
        "    texto = remover_acentos(texto.lower())\n",
        "    texto = re.sub(r'[^a-z0-9\\s]', '', texto)\n",
        "    palavras = texto.split()\n",
        "    palavras = [word for word in palavras if word not in stop_words_manual]\n",
        "    return ' '.join(palavras)\n",
        "\n",
        "def classificar_frase(frase):\n",
        "    frase_preprocessada = preprocessar_texto(frase)\n",
        "    frase_vectorizada = vectorizer.transform([frase_preprocessada])\n",
        "    previsao = modelo.predict(frase_vectorizada)\n",
        "\n",
        "    if previsao[0] == 0:\n",
        "        return \"0 - Pedido considerado falso\"\n",
        "    else:\n",
        "        return \"1 - O pedido parece verídico\"\n",
        "\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=classificar_frase,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Digite a descrição do pedido aqui...\", label=\"Descrição do Pedido\"),\n",
        "    outputs=gr.Textbox(label=\"Classificação\"),\n",
        "    title=\"Classificador de Pedidos\",\n",
        "    description=\"Digite uma descrição para verificar se o pedido é verdadeiro ou falso.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "o34MRSdN83tH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}